# 自动驾驶:优步和特斯拉

> 原文:[https://hackaday.com/2018/04/02/self-driven-uber-and-tesla/](https://hackaday.com/2018/04/02/self-driven-uber-and-tesla/)

过去两周，自动驾驶汽车在新闻中出现了很多。3 月 18 日，优步的自动驾驶出租车撞死了一名行人，就在几天后，一辆在“自动驾驶”模式下运行的特斯拉全速撞上了路障，导致司机死亡。在这两种情况下，都有一名人类司机应该站在机器的肩膀上看着，但在优步的情况下，司机[似乎已经分心](https://www.sfgate.com/business/article/Uber-s-self-driving-cars-were-struggling-before-12777769.php)，而在特斯拉的情况下，司机[在撞车](https://www.tesla.com/blog/update-last-week%E2%80%99s-accident?redirect=no)之前把手从方向盘上拿开了六秒钟。自动驾驶汽车有多安全？

绝招问题！至少从某种意义上来说，这两款车都不是“自动驾驶”的:都有一个人最终负责驾驶车辆。优步和特斯拉的驱动系统甚至没有可比性。优步出租车做路线和规划，知道速度限制，并且*应该*能够看到红色交通灯并停在那里(下面有更多信息！).特斯拉的“自动驾驶”系统实际上只是自适应巡航控制和车道保持子系统的结合，这甚至不足以让它在加利福尼亚州被归类为自动驾驶。事实上，这是方向盘后面的人的失败，以及对这些人进行适当培训的失败，这使得驾驶员和自动驾驶汽车的结合比单独的人类驾驶员更加危险。

[![](../Images/ea6effb22c731d6a07fa75f1e43fb381.png)](https://hackaday.com/wp-content/uploads/2018/04/uber.jpg)

A self-driving Uber Volvo XC90, San Francisco.

你仍然可以想象想要挖掘自动驾驶汽车安全记录的数据，即使它们是异质的，并且有人在扮演机械土耳其人。如果你做了，你会非常失望。没有一家制造商在不必要的时候公开发布他们的任何数据。事实上，我们对这些公司自动驾驶汽车数据的一瞥来自两个来源:泄露给媒体的内部文件和公司公关部门精心挑选的统计数据。加利福尼亚州要求[在任何地方对自动驾驶汽车](https://www.dmv.ca.gov/portal/dmv/detail/vr/autonomous/)进行最严格的记录，这是另一个来源，但因为特斯拉的汽车不是自动驾驶的，而且因为优步拒绝承认其汽车对加州 DMV 是自动驾驶的，所以我们对这两个车辆平台没有额外的了解。

尽管如此，特斯拉的自动驾驶仪现在已经发生了三起死亡事故，而且都有一个共同点——三名司机都非常信任车道保持功能，在生命的最后几秒钟没有控制方向盘。在优步，几乎没有自动驾驶汽车的性能历史，但有泄露的文件和一种模式，让优步看起来像一个冒险的藐视法律者，拥有低于标准的技术，有既得利益使它看起来比实际情况更好。这些车辆在公共道路上自由行驶，没有额外的监管，其他交通参与者被当作安全试验品，这给自动驾驶汽车行业和 ideal 带来了负面影响。

如果特斯拉和优步的汽车技术非常不同，那么这两家公司有一些共同点。它们都是由特立独行者掌舵的“颠覆性”公司，认为自己的命运取决于自动驾驶技术的广泛部署。但具有讽刺意味的是，优步和特斯拉与谷歌和通用汽车的最大区别在于，它们在车辆中使用了基本上未经训练的试飞员:特斯拉是以消费者的形式出现的，而优步是以出租车司机的形式出现的，他们几乎没有受过专门的自动驾驶汽车培训。导致特斯拉和优步事故的原因可能更多地与人为因素有关，而不是自动驾驶技术本身。

你可以看到我们有很多内容要讲。请继续阅读！

## 红鲱鱼

但首先，这里有一些不相关的统计数据，你会在事故发生后听到这些数据被取笑。首先是“超过 90%的事故是由人类司机造成的”。这并不奇怪，因为所有的汽车司机都是人。当只有自动驾驶汽车被允许上路时，他们将对 100%的事故负责。唯一重要的是人类和机器的相对安全性，以每英里、每次旅行或每小时来表示。让我们来谈谈这个。

[![](../Images/05deb291b5850bc75ef2d72429b097d1.png)](https://hackaday.com/wp-content/uploads/2018/04/rand_fatalities.jpg)

From phenominal RAND [report on self-driving cars.](https://www.rand.org/pubs/research_reports/RR443-2.html)

据报道，人类是糟糕的司机，因为去年美国高速公路上有 35，000 人死亡。这实际上证明了人们非常擅长驾驶，尽管他们有缺点。在此过程中，美国司机也行驶了 3 万亿英里。你要记住的三个相关统计数据作为基线:每起死亡事故 90 *百万*英里，每起受伤事故 100 万英里，每起事故 50 万英里。当自动驾驶汽车能够击败这些数字时，这些数字包括醉酒司机、下雪和下雨的天气条件以及手机，你可以说人类是“糟糕的”司机。(来源:[美国国家公路交通安全管理局。](https://www-fars.nhtsa.dot.gov/Main/index.aspx))

最后，我肯定你已经听说过自动驾驶汽车“将”比人类司机更安全，现在的一些致命事故只是一个令人不安的驼峰，我们必须克服它才能在未来拯救数百万人的生命。这是一个“目的证明手段正当”的论点，一开始就把它放在粗略的道德基础上。此外，在医学试验中，患者需要给予接受治疗的[知情同意](https://en.wikipedia.org/wiki/Informed_consent)，并且必须证明正在考虑的治疗[不会比已经使用的治疗](https://dx.doi.org/10.3345%2Fkjp.2012.55.11.403)差很多。自动驾驶技术的测试并没有那么不同，我们也没有签署同意与非人类驾驶员共享道路的同意书。更糟糕的是，看起来机器没有我们好。遮羞布是，人类司机最终是在控制，所以它可能不会比让他们在没有机器的情况下驾驶更糟，对不对？让我们来看看。

## 特斯拉:自动驾驶，但不是自动驾驶

[![](../Images/2617e502d6f98020eedc478b01013a23.png)](https://hackaday.com/wp-content/uploads/2018/04/tesla-wreck.jpg) 

【图片:[electr ek](https://electrek.co/2018/03/27/tesla-model-x-fatal-crash-ntsb-investigation-autopilot-fire/)

我查阅了[特斯拉的“自动驾驶”安全记录就在第二起致命事故](https://hackaday.com/2016/12/05/self-driving-cars-are-not-yet-safe/)之后；什么都没有改变。特斯拉增加了第三起死亡事故，但在自动驾驶下也可以再行驶 1 亿英里(他们没有说，所以我们假设他们的平均水平没有显著提高)。很可能特斯拉的自动驾驶仪的平均死亡率与美国总人口大致相同，约为 9000 万英里，但在他们跑了几十亿英里之前，我们无法建立统计上的信心。

这不太好。自动驾驶应该只在良好的天气条件下，在良好的路段上使用，并受到严格的监督。如果考虑人类如何在这些最佳条件下驾驶，他们也会比平均水平好得多。大约 30%的致命事故发生在十字路口,这应该会让自动驾驶的传统高速公路巡航用例看起来好很多。基于这些因素，一个有根据的猜测是，在相同的情况下，自动驾驶并不比普通的人类司机差多少，但它肯定也不会明显更好。

[![](../Images/efde4a107b7715eac195b9c055aa1651.png)](https://hackaday.com/wp-content/uploads/2016/11/tesla-autopilot-road-trip-nqnjro4fqnomp4-shot0001.jpg)

Perhaps the public perception of “hand-on” driving technology needs adjustment

但是自动驾驶并不是自动的。根据自动化的 SAE 定义，目前的自动驾驶软件是 2 级，部分自动化，这是危险的。因为这个系统在大多数时候都运行得很好，所以用户可能会忘记他们应该一直处于控制之中。这是[美国国家运输安全委员会(NTSB)对 2016 年事故的结论](https://www.ntsb.gov/news/press-releases/Pages/PR20170912.aspx)的一部分，也是所有三起自动驾驶相关死亡事件的共同线索。当系统未能发现障碍时，司机没有把手放在方向盘上，准备接管。他们过度依赖系统工作。

很难责怪他们。在经历了数千次汽车做正确的事情后，很难在第 4023 次进行第二次猜测。具有讽刺意味的是，如果系统有大量的侥幸脱险，这将变得更加困难。如果系统经常在你拥有后不久做出[正确的选择，你要学会抑制你的不信任。你练习不干涉每一次未遂事件。这也是](https://www.greencarreports.com/news/1106509_ca-to-restrict-use-of-term-autopilot-tesla-owning-pilot-weighs-in/page-2)[消费者报告呼吁特斯拉取消转向功能和自动驾驶名称](https://www.consumerreports.org/media-room/press-releases/2016/07/consumer-reports-calls-on-tesla-to-disable-and-update-auto-steering-function-remove-autopilot-name/)的原因——它只是承诺太多了。

## 优步:藐视法律和混乱

你可能会说现在指责优步是卑鄙的。毕竟，他们刚刚经历了一场悲剧，这也许是不可避免的。但是，尽管特斯拉正在向自动化迈出小步，也许推动它们太难了，但优步似乎正在迈出巨大的步伐，打破法律，推动他们的司机，并希望最好的。

2016 年 12 月，优步宣布将在加州测试其车辆。只有一个障碍:他们不被允许。加州车管所将他们的车辆归类为自动驾驶，这使得他们必须遵守报告要求(稍后将详细介绍！)优步人[不愿意让自己受制于](https://www.theverge.com/2017/2/27/14698902/uber-self-driving-san-francisco-dmv-email-levandowski)，所以优步辩称，根据加州法律，他们的汽车不是自动驾驶的，而且他们还是在开车。

[![](../Images/aa147f1ab47de6904f16ff72d219091f.png)T2】](https://hackaday.com/wp-content/uploads/2018/04/self-driving-uber-running-red-light-_cdj4oae8f4mp4-shot0001.jpg)

仅仅几天后，旧金山市就关闭了它们。据报道，他们在旧金山街头的一周内，他们的汽车闯了五六次红灯，至少有一次被警察拍了下来(当然还有被上传到 YouTube 上的)。优步声称，司机没有超越汽车是错误的，显然根本没有看到灯。

在天堂制造的宣传噱头中，优步把他们的汽车装上一辆“奥托”牌大卡车，向南开往亚利桑那州。接招吧，加州！只有奥托卡车由人类司机驾驶，这与在内华达州拍摄的著名的奥托卡车自动驾驶视频形成了鲜明的对比。(在此期间，他们也没有自主经营的适当许可，因此在拍摄时是非法经营的。)

像许多自动驾驶汽车公司一样，优步选择了亚利桑那州，因为那里有良好的天气、宽阔的高速公路和宽松的监管。亚利桑那州州长道格拉斯·杜西(Douglas Ducey)确保该州“对商业开放”，并对自驾者施加最低限度的限制，只要他们遵守交通规则。值得注意的是，在亚利桑那州没有*的报告要求，一旦许可被批准也没有监督。*

事故发生前他们的车在亚利桑那州表现如何？不太好。根据泄露的内部文件，当司机需要接管时，他们平均间隔 13 英里进行“干预”。有了 Autopilot，我们推测被一次几乎太好的经历所麻痹而自满的危险，但这是相反的。我们不知道有多少干预是严重的问题，比如没有注意到行人或红灯，也不知道有多少是轻微的问题，比如在空旷的道路上稍微偏离车道，或者只是没有平稳地刹车。但我们知道一名优步车手必须时刻保持警惕。在这种高需求的环境下，他们将司机的数量从两个减少到一个，以降低成本。

[![](../Images/71f4ee0f616c1020776b0131a0821745.png)](https://hackaday.com/wp-content/uploads/2018/04/uber-driver.png)

This human will take the heat. Uber and Arizona are responsible.

然后是事故。当时，优步汽车总共行驶了 300 万英里。还记得美国平均每死亡人数超过 9000 万英里吗？也许优步运气不好，但鉴于他们的背景，我不愿意给他们带来好处。尽管如此，要计算自动驾驶汽车的 300 万英里无事故行驶里程也是一种挑战。300 万英里，每次干预 13 英里，意味着一个人控制了大约 23 万次。我们不知道其中有多少包括司机在一次事故发生前阻止了一次严重事故的情况。这不是比人类驾驶更好的样子。

## 外卖食品

其他自动驾驶汽车技术的性能记录要好得多，没有死亡事故，或者通过在加州测试车辆，接受了哪怕是最轻微的公众审查，加州是唯一一个对自动驾驶汽车有披露要求的州。随着加州一项规定生效(今天！)实现自动驾驶汽车的全面部署，而不仅仅是在该州进行测试，我们预计未来会看到更多数据。我会在另一篇文章中写下自驾车的好处。

但是现在，我们只剩下两个重要的反例。如果他们的车辆性能没有(强制)透明度，就不能指望这个行业进行自我监管——特斯拉和优步都认为他们正在进行一场赢家通吃的自动驾驶比赛，并且正在偷工减料。

因为没有无人驾驶汽车，即使是最好中的最好，也无法在没有人类干预的情况下行驶超过几千英里，人类是薄弱环节。但这并不是因为人们是糟糕的司机这一常见原因——我们正在谈论的是人类引导的自动驾驶汽车终究无法达到无人帮助的人类的安全标准。相反，我们需要公开承认，驾驶“自动驾驶”汽车是一项独特而危险的任务。飞机飞行员接受大量关于(真正的)自动驾驶仪的使用和局限性的训练。也许是时候让自动驾驶驾驶员也强制执行这一规定了。

不管怎样，公众应该得到更多的数据。从所有证据来看，以任何标准来看，自动驾驶汽车的当前技术水平都远没有人类司机安全，然而，街道上正在进行潜在的致命实验。获得所有驾驶员的知情同意来参与这个实验也许要求太多了。但至少我们应该得到通知。