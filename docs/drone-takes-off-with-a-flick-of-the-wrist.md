# 手腕一抖，无人机就起飞了

> 原文：<https://hackaday.com/2017/06/18/drone-takes-off-with-a-flick-of-the-wrist/>

手势跟踪是增强现实发展领域中的一项配套技术。将某人置于虚拟或增强世界是一回事，但如果没有一种自然的交互方式，用户体验可能会受到限制。当然，手势也可以用来控制现实世界中的事情，为此[Sarah]的最新项目使用[这种有趣的人机界面设备来控制无人机](https://forums.ni.com/t5/Example-Program-Drafts/myWingman-Gesture-Controlled-Drone/ta-p/3644689)。

该项目使用 Leap Motion 传感器来检测和收集手势数据，并将所有信息输入 LabVIEW。这个项目选择了 Parrot AR 无人机，因为它有一个健壮的 API，可以与这个特定的软件套件很好地配合。看起来好像许多识别手势和向无人机发送命令的繁重工作都是在软件的幕后进行的，所以如果你想自己完成这项工作，可能会有更多的工作要做。也就是说，首先让它工作起来并不容易，下面的视频值得一看。

对一些人来说，手势可能看起来像一种没有实际应用的新奇技术，但对于残疾人或其他需要免提方法的特殊工作流程的人来说，手势确实有实际用途。到目前为止，我们已经看到了手势技术，例如[驾驶汽车](http://hackaday.com/2016/04/05/hand-gestures-drive-car/)，帮助人们[在现实世界中四处走动](http://hackaday.com/2015/09/14/head-gesture-tracking-helps-limited-mobility-students/)，甚至[玩俄罗斯方块](http://hackaday.com/2016/05/28/hand-gestures-play-tetris/)。

 [https://www.youtube.com/embed/AlsrSwjUddI?version=3&rel=1&showsearch=0&showinfo=1&iv_load_policy=1&fs=1&hl=en-US&autohide=2&wmode=transparent](https://www.youtube.com/embed/AlsrSwjUddI?version=3&rel=1&showsearch=0&showinfo=1&iv_load_policy=1&fs=1&hl=en-US&autohide=2&wmode=transparent)

