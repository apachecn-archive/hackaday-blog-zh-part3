# 人工智能的简史，以及它为什么走向错误的方向

> 原文:[https://hack aday . com/2015/12/01/a-人工智能的短暂历史及其走向错误方向的原因/](https://hackaday.com/2015/12/01/a-short-history-of-ai-and-why-its-heading-in-the-wrong-direction/)

温斯顿·丘吉尔爵士经常把第二次世界大战称为“巫师战争”。盟军和轴心国都在战场上竞相争取电子优势。在此期间诞生了许多技术——其中之一就是破译加密信息的能力。能够实现这一壮举的设备是现代计算机的前身。1946 年，美军研制出了 [ENIAC](https://en.wikipedia.org/wiki/ENIAC) ，即电子数字积分器和计算机。ENIAC 使用 17，000 多个真空管，比所有以前的机电计算机快几个数量级。然而，让许多科学家兴奋的是，它是可编程的*。正是可编程计算机的概念引发了人工智能(AI)的 [![ai_05](../Images/a1fab772914c759acfb5d678856f1636.png)](https://en.wikipedia.org/wiki/ENIAC) 想法。*

 *随着时间的推移，计算机变得越来越小，越来越快。半导体晶体管的发明产生了微处理器，这加速了计算机编程的发展。人工智能开始加速，专家们开始大言不惭地宣称计算机智能将很快超越我们人类。像伊莱扎和 T2 积木世界这样的程序让公众着迷，并给人一种感觉，当计算机变得更快时，它们将能够像人类一样思考，这在未来是肯定的。

但很快就清楚了，事实并非如此。虽然这些和许多其他人工智能程序擅长它们所做的事情，但它们或它们的算法都没有适应性。他们在特定的任务中很“聪明”，从他们的行为来看甚至可以被认为是聪明的，但他们对任务没有理解，甚至连典型的实验室老鼠的智力都比不上，更不用说人类了。

## 神经网络

随着人工智能在 20 世纪 80 年代末逐渐消失，它允许神经网络研究人员获得一些急需的资金。神经网络自 20 世纪 60 年代以来就已经存在，但被人工智能研究积极压制。由于资源匮乏，神经网络鲜为人知，直到人工智能显然没有达到宣传的效果。与最初的人工智能所基于的计算机不同，神经网络没有处理器或存储记忆的中心位置。

![Deep Blue computer](../Images/3ef319f237840339290825871e76047d.png)

Deep Blue computer

神经网络不像计算机那样被编程。它们以某种方式连接在一起，赋予它们学习输入的能力。这样，它们就类似于哺乳动物的大脑。毕竟，在大图中，大脑只是一堆以高度特定的模式连接在一起的神经元。神经网络与大脑的相似之处让他们获得了那些对基于计算机的人工智能失望的人的关注。

在 20 世纪 80 年代中期，一家名为 [NETtalk](https://en.wikipedia.org/wiki/NETtalk_%28artificial_neural_network%29) 的公司建立了一个神经网络，至少在表面上，它能够学习阅读。它能够做到这一点是通过学习将字母模式映射到口语。过了一会儿，它学会了说单个单词。NETtalk 被誉为人类智慧的胜利，占据了全世界的新闻头条。但是从工程学的角度来看，它做的事情一点也不难。它没有*理解*任何事情。它只是把模式和声音匹配起来。然而，它确实学会了，这是基于计算机的人工智能很难学会的。

最终，神经网络将遭受与基于计算机的人工智能相似的命运——大量的宣传和兴趣，只是在它们无法产生人们预期的结果后逐渐消失。

## 新的世纪

在进入 21 世纪的过渡中，人工智能的发展几乎没有什么进展。1997 年，IBM 公司的“深蓝”在一系列国际象棋比赛中击败了加里·卡斯帕罗夫，成为短暂的头条新闻。但是深蓝并不是因为聪明才赢的。它赢了，因为它只是更快。深蓝不懂象棋，就像计算器不懂数学一样。

![ai_04](../Images/48b76cfe67b63b8c8ee25f4cea42da44.png)

Example of Google’s Inceptionism. The image is taken from the middle of the hierarchy during visual recognition.

现代已经看到了很多相同的人工智能方法。谷歌正在使用与分层结构相结合的神经网络，并取得了一些有趣的发现。其中之一是一个叫做[概念主义](http://hackaday.com/2015/06/24/inceptionism-mind-blown-by-what-neural-nets-think-they-see/)的过程。神经网络很有前途，但它们仍然没有显示出通往真正人工智能的清晰道路。

IBM 的沃森能够击败一些《危险边缘》的顶级玩家。人们很容易认为沃森很“聪明”，但事实远非如此。沃森通过搜索兆兆字节的信息非常快速地获得答案。它没有能力真正理解自己在说什么。

人们可以说，多年来试图创造人工智能的过程影响了我们对它的定义，甚至到今天也是如此。尽管我们都认同“人工”这个术语的含义，但定义“智能”实际上是什么却给这个难题带来了另一层含义。看看过去智力是如何被定义的，将会给我们一些启示，我们是如何未能实现它的。

## 艾伦·图灵和中国室

现代计算之父艾伦·图灵发明了一种简单的测试来判断计算机是否有智能。这就是所谓的图灵测试，大概是这样的:如果一台计算机可以和一个人交谈，而这个人认为他或她是在和另一个人交谈，那么我们可以说这台计算机模仿了一个人，可以说它拥有智能。上面提到的 ELIZA 程序用这个测试愚弄了一小撮人。图灵对智力的定义是基于行为的，并且被接受了很多年。这种情况在 1980 年发生了变化，当时约翰·塞尔提出了他的“中国房间”论点。

设想一个说英语的人被锁在一个房间里。房间里有一张桌子，桌子上有一本大书。这本书是用英语写的，并且有如何操作汉字的说明。他不知道这是什么意思，但他能按照指示做。然后有人在门下塞了一张纸。纸上是一个故事和关于这个故事的问题，都是用中文写的。这个人一个字也不懂，但是能够用他的书来操纵汉字。他用他的书填写问题，然后把纸从门下递回来。

另一边说中文的人阅读答案，并确定它们都是正确的。她得出结论，房间里的那个人懂中文。然而，对我们来说很明显，这个人不懂中文。那么思想实验的意义是什么呢？

这个人是一个加工者。这本书是一个程序。门下的纸是输入。处理器将程序应用于输入并产生输出。这个简单的思维实验表明，计算机永远不能被认为是智能的，因为它永远无法理解自己在做什么。它只是遵循指示。智慧在于书的作者或程序员。不是人或处理器。

## 智力的新定义

在所有人类对人工智能的追求中，他一直并且积极地寻找行为作为智能的定义。但是约翰·塞尔向我们展示了一台计算机是如何产生智能行为而仍然不智能的。如果人或处理器不知道自己在做什么，它怎么可能是智能的呢？

以上所说的都是为了划清行为和理解之间的界限。智力不能由行为来定义。行为是智力的表现，仅此而已。想象一下躺在一个黑暗的房间里一动不动。你会思考，因此很聪明。但是你没有产生任何行为。

智力应该由理解的能力来定义。《关于智力的 的 *[一书的作者【杰夫·霍金斯】开发了一种通过预测做到这一点的方法。他称之为](https://en.wikipedia.org/wiki/On_Intelligence)[记忆预测框架](https://en.wikipedia.org/wiki/Memory-prediction_framework)。想象一个系统不断地试图预测接下来会发生什么。当一个预测被满足时，函数被满足。当预测不符合时，焦点指向异常，直到它可以被预测。例如，当你坐在办公桌前时，你会听到宠物项圈的叮当声。你转向门口，预测你会看到你的宠物走进来。只要符合这个预测，一切正常。很可能你没有意识到这样做。但是如果这个预测被违反了，它会让这个场景成为焦点，你会调查为什么你没有看到你的宠物走进来。*

这个不断尝试预测你的环境的过程让你了解它。智慧的本质是预测，而不是行为。如果我们可以对计算机或神经网络进行编程，使其遵循预测范式，它就可以真正理解其环境。而正是这种理解，才会让机器变得智能。

所以现在轮到你了。你如何定义人工智能中的“智能”？*