# 幻觉机器产生微小的视频片段

> 原文:[https://hack aday . com/2016/09/29/幻觉-机器-生成-微小-视频-剪辑/](https://hackaday.com/2016/09/29/hallucinating-machines-generate-tiny-video-clips/)

幻觉是对实际上不存在的东西的错误感知——或者换句话说:对训练数据的一种可能解释。来自麻省理工学院和 UMBC 的研究人员开发并训练了一个生成机器学习模型，该模型学习随机生成微小视频。这种幻觉般的 64×64 像素的小剪辑看起来有些可信，但也有点怪异。

[![](../Images/b83e94d44bad294702929d8d0fc8b7ab.png)](https://hackaday.com/2016/09/29/hallucinating-machines-generate-tiny-video-clips/10-7/)[![](../Images/d743b40e851206f323e7bc49e314b9d1.png)](https://hackaday.com/2016/09/29/hallucinating-machines-generate-tiny-video-clips/1-24/)[![](../Images/f4ace06141522b7c76a4a4dba89b56f3.png)](https://hackaday.com/2016/09/29/hallucinating-machines-generate-tiny-video-clips/11-1/)[![](../Images/420d46c5dc65c77e3bf69ee24ef74b48.png)](https://hackaday.com/2016/09/29/hallucinating-machines-generate-tiny-video-clips/13-5/)[![](../Images/5fa2631b77562de50deb9ab24a533171.png)](https://hackaday.com/2016/09/29/hallucinating-machines-generate-tiny-video-clips/5-15/)[![](../Images/f6dcbaf0980f64406a3da4f971a23e61.png)](https://hackaday.com/2016/09/29/hallucinating-machines-generate-tiny-video-clips/3-18/)[![](../Images/e2a6d7f23a01d2bd9932d46414ea25ce.png)](https://hackaday.com/2016/09/29/hallucinating-machines-generate-tiny-video-clips/10-1/)[![](../Images/b4750d38544afabb842bac218400e265.png)](https://hackaday.com/2016/09/29/hallucinating-machines-generate-tiny-video-clips/11-5/)[![](../Images/b2da458d3f794ba79db6ecb688538c19.png)](https://hackaday.com/2016/09/29/hallucinating-machines-generate-tiny-video-clips/2-22/)

这些人工剪辑背后的机器学习模型能够从未标记的“野外”训练视频中学习，并且主要依赖于后续帧的时间一致性以及静态背景的存在。它学习将前景物体从背景中分离出来，并从场景中提取整体动态。然后，训练好的模型可以用于随机生成新的剪辑(如上所示)，或者从静态输入图像生成新的剪辑(如下成对所示)。

[![](../Images/facc37ffcee56057f31769ca3f83e564.png)](https://hackaday.com/2016/09/29/hallucinating-machines-generate-tiny-video-clips/3_input/)[![](../Images/8db4e15e9e233309a46ff8f0f7a3d562.png)](https://hackaday.com/2016/09/29/hallucinating-machines-generate-tiny-video-clips/3_us/)[![](../Images/4c02db92a30ae0021bc5db5a2cbb7109.png)](https://hackaday.com/2016/09/29/hallucinating-machines-generate-tiny-video-clips/4_input/)[![](../Images/56d3cd87a42d0391103e65844fd80933.png)](https://hackaday.com/2016/09/29/hallucinating-machines-generate-tiny-video-clips/4_us/)[![](../Images/c587852ecd2144111aa045b041ee3819.png)](https://hackaday.com/2016/09/29/hallucinating-machines-generate-tiny-video-clips/9_input/)[![](../Images/d1745e48a015a68c4ce2e6a2ea3b8716.png)](https://hackaday.com/2016/09/29/hallucinating-machines-generate-tiny-video-clips/9_us/)[![](../Images/afeeafb2b3bd558f40bb58da1e70b4cb.png)](https://hackaday.com/2016/09/29/hallucinating-machines-generate-tiny-video-clips/11_input/)[![](../Images/a9eef516bd168d9ac42cb16bd2cf8981.png)](https://hackaday.com/2016/09/29/hallucinating-machines-generate-tiny-video-clips/11_us/)

目前，该团队将剪辑的分辨率限制为 64×64 像素，持续时间为 32 帧，以减少所需的训练数据量，目前仍为 7 TB。尽管在真实感方面存在明显的缺陷，但在该团队进行的心理物理学研究中，约 20%的参与者认为这些小片段比真实片段“更真实”。该项目的代码(Torch7/LuaJIT)已经可以在 GitHub 上找到[，还有一个预先训练好的模型。该项目还将于 12 月在](https://github.com/cvondrick/videogan) [2016 NIPS 会议](https://nips.cc/)上展示。