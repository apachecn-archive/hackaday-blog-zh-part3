# 无人驾驶汽车的可预测性问题

> 原文:[https://hack aday . com/2016/04/18/自动驾驶汽车的可预测性问题/](https://hackaday.com/2016/04/18/the-predictability-problem-with-self-driving-cars/)

一位法学教授和一位工程学教授走进一家酒吧。这是一篇关于自动驾驶汽车的负面影响以及如何应对的细致入微的文章。他们论文的简短版本:为了共存，自动驾驶汽车需要对人类更加可预测。

我们和许多机器共享生活空间。它们中的许多是可移动的和危险的，但是完全在人类的控制之下:例如汽车。当我们想知道十字路口的另一辆车要做什么时，我们会想到那辆车的司机，甚至可能会进行眼神交流，看他们是否看到了我们。然后，我们会考虑在他们的位置上我们会做什么，交通状况会相应地得到改善。

当谷歌的无人驾驶汽车在 2 月发生事故时，谷歌回答说“我们的测试司机认为汽车会减速或停下来让我们融入车流，并且会有足够的空间这样做。”显然，那辆车也是，就在它驶出一辆迎面而来的公共汽车之前。公共汽车司机也没想到汽车会(慢慢地)驶入车道。

迄今为止，所有其他自动驾驶汽车事故都是其他司机的错，作者认为这很能说明问题。如果你意外地一直刹车，你可能最终会被从后面撞上。如果人们不能读懂你的车的人工智能的思想，你会得到你的挡泥板弯曲。

[![](../Images/6576baa872a06be6b49b04fe93615d0f.png)](https://hackaday.com/wp-content/uploads/2016/04/87685764_1c5784b9-2f8d-44d5-bbd6-bac13893236f_fixed.jpg) 这篇论文的解决方案是让自动驾驶汽车更可预测，他们提到了许多显而易见的解决方案，从“我-感知-你”灯到车际通信。但是还有一些方面我们没有考虑到:例如，表明人工智能能力的特定标记。发出左转信号的自行车手很想知道后面的车在进入车道前是否有新的自行车手信号识别升级。将你的注意力放在另一辆车上的能力是至关重要的，这需要大量关于司机的信息。

所有这些都可能需要和涉及立法。除了法律的非黑即白之外，意图和事故各方“应该知道”的东西在法庭上被用来分配责任。当其中一方是人工智能时，情况会变得更加模糊。你怎么知道算法应该在想什么？这远远不是一个已经解决的问题，它变得越来越重要。

我们以前写过自动驾驶汽车的[伦理，但只是简单地从它们的决策能力来看。这篇论文提出了一个观点，即我们也需要能够理解他们在想什么，这既是一个技术问题，也是一个人际互动和法律问题。](http://hackaday.com/2015/10/29/the-ethics-of-self-driving-cars-making-deadly-decisions/)

[头条图片:[谷歌自动驾驶汽车项目](https://www.google.com/selfdrivingcar/)